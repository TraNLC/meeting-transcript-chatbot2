{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš€ WhisperX API Server - Zero Cost Meeting Transcription\n",
        "\n",
        "**HÆ°á»›ng dáº«n sá»­ dá»¥ng:**\n",
        "1. Chá»n Runtime > Change runtime type > GPU (T4)\n",
        "2. Cháº¡y táº¥t cáº£ cells (Runtime > Run all)\n",
        "3. Copy URL ngrok hiá»ƒn thá»‹ bÃªn dÆ°á»›i\n",
        "4. DÃ¡n vÃ o config cá»§a Meeting App\n",
        "5. Sau khi há»p xong, táº¯t Colab"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: CÃ i Ä‘áº·t thÆ° viá»‡n\n",
        "!pip install whisperx flask pyngrok python-dotenv -q\n",
        "!pip install faster-whisper -q\n",
        "print(\"âœ… CÃ i Ä‘áº·t hoÃ n táº¥t!\")"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import vÃ  Setup\n",
        "from flask import Flask, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import whisperx\n",
        "import gc\n",
        "import torch\n",
        "import os\n",
        "from threading import Thread\n",
        "\n",
        "# Cáº¥u hÃ¬nh ngrok token (Láº¥y free táº¡i: https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "NGROK_AUTH_TOKEN = \"YOUR_NGROK_AUTH_TOKEN\"  # âš ï¸ THAY Äá»”I TOKEN NÃ€Y\n",
        "\n",
        "# Cáº¥u hÃ¬nh HuggingFace token (Láº¥y táº¡i: https://huggingface.co/settings/tokens)\n",
        "HF_TOKEN = \"YOUR_HF_TOKEN\"  # âš ï¸ THAY Äá»”I TOKEN NÃ€Y (cáº§n cho diarization)\n",
        "\n",
        "app = Flask(__name__)\n",
        "port = 5000\n",
        "\n",
        "print(\"ðŸ”§ Äang khá»Ÿi táº¡o...\")"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load WhisperX Model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 16\n",
        "compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
        "\n",
        "print(f\"ðŸŽ¯ Device: {device}\")\n",
        "print(\"ðŸ“¦ Äang load WhisperX model (large-v3)...\")\n",
        "model = whisperx.load_model(\"large-v3\", device, compute_type=compute_type)\n",
        "print(\"âœ… Model loaded!\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: API Endpoints\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health_check():\n",
        "    return jsonify({\n",
        "        \"status\": \"healthy\",\n",
        "        \"device\": device,\n",
        "        \"model\": \"whisperx-large-v3\"\n",
        "    })\n",
        "\n",
        "@app.route('/transcribe', methods=['POST'])\n",
        "def transcribe_audio():\n",
        "    try:\n",
        "        if 'file' not in request.files:\n",
        "            return jsonify({\"error\": \"No file uploaded\"}), 400\n",
        "        \n",
        "        file = request.files['file']\n",
        "        if file.filename == '':\n",
        "            return jsonify({\"error\": \"Empty filename\"}), 400\n",
        "        \n",
        "        # LÆ°u file táº¡m\n",
        "        temp_path = \"/tmp/temp_audio.wav\"\n",
        "        file.save(temp_path)\n",
        "        \n",
        "        print(f\"ðŸ“ Processing: {file.filename}\")\n",
        "        \n",
        "        # 1. Load audio\n",
        "        audio = whisperx.load_audio(temp_path)\n",
        "        \n",
        "        # 2. Transcribe\n",
        "        print(\"ðŸŽ¤ Transcribing...\")\n",
        "        result = model.transcribe(audio, batch_size=batch_size)\n",
        "        \n",
        "        # 3. Align (tÄƒng Ä‘á»™ chÃ­nh xÃ¡c timestamp)\n",
        "        print(\"â±ï¸ Aligning timestamps...\")\n",
        "        model_a, metadata = whisperx.load_align_model(\n",
        "            language_code=result[\"language\"], \n",
        "            device=device\n",
        "        )\n",
        "        result = whisperx.align(\n",
        "            result[\"segments\"], \n",
        "            model_a, \n",
        "            metadata, \n",
        "            audio, \n",
        "            device, \n",
        "            return_char_alignments=False\n",
        "        )\n",
        "        \n",
        "        # 4. Diarization (phÃ¢n biá»‡t ngÆ°á»i nÃ³i)\n",
        "        print(\"ðŸ‘¥ Diarizing speakers...\")\n",
        "        if HF_TOKEN and HF_TOKEN != \"YOUR_HF_TOKEN\":\n",
        "            diarize_model = whisperx.DiarizationPipeline(\n",
        "                use_auth_token=HF_TOKEN, \n",
        "                device=device\n",
        "            )\n",
        "            diarize_segments = diarize_model(audio)\n",
        "            result = whisperx.assign_word_speakers(diarize_segments, result)\n",
        "        else:\n",
        "            print(\"âš ï¸ Bá» qua diarization (chÆ°a cÃ³ HF_TOKEN)\")\n",
        "        \n",
        "        # Clean up\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        os.remove(temp_path)\n",
        "        \n",
        "        print(\"âœ… Done!\")\n",
        "        \n",
        "        return jsonify({\n",
        "            \"success\": True,\n",
        "            \"language\": result.get(\"language\", \"unknown\"),\n",
        "            \"segments\": result[\"segments\"]\n",
        "        })\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {str(e)}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "print(\"âœ… API endpoints ready!\")"
      ],
      "metadata": {
        "id": "api"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Start Server vá»›i ngrok\n",
        "\n",
        "# Setup ngrok\n",
        "if NGROK_AUTH_TOKEN and NGROK_AUTH_TOKEN != \"YOUR_NGROK_AUTH_TOKEN\":\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    public_url = ngrok.connect(port)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸš€ SERVER ÄANG CHáº Y!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"ðŸ“¡ Public URL: {public_url}\")\n",
        "    print(f\"\\nâœ… Copy URL nÃ y vÃ  dÃ¡n vÃ o config cá»§a Meeting App\")\n",
        "    print(f\"\\nðŸ“ Test endpoint:\")\n",
        "    print(f\"   GET  {public_url}/health\")\n",
        "    print(f\"   POST {public_url}/transcribe\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "else:\n",
        "    print(\"âš ï¸ Cáº¢NH BÃO: ChÆ°a cáº¥u hÃ¬nh NGROK_AUTH_TOKEN!\")\n",
        "    print(\"ðŸ‘‰ Láº¥y token táº¡i: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "    print(\"ðŸ‘‰ Sau Ä‘Ã³ sá»­a Cell 2 vÃ  cháº¡y láº¡i\")\n",
        "\n",
        "# Start Flask server\n",
        "def run_flask():\n",
        "    app.run(port=port, debug=False, use_reloader=False)\n",
        "\n",
        "thread = Thread(target=run_flask)\n",
        "thread.start()\n",
        "\n",
        "print(\"\\nðŸ’¡ Server sáº½ cháº¡y cho Ä‘áº¿n khi báº¡n dá»«ng Colab notebook nÃ y\")\n",
        "print(\"ðŸ’¡ Sau khi há»p xong, nhá»› Runtime > Disconnect and delete runtime\")"
      ],
      "metadata": {
        "id": "start_server"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
