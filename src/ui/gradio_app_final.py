"""Final Gradio UI - Best of both worlds: Working logic + Beautiful design."""

import gradio as gr
import sys
from pathlib import Path
from datetime import datetime

# Add src to path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.config import Settings
from src.data import TranscriptLoader, TranscriptPreprocessor
from src.data.history_manager import HistoryManager
from src.llm import LLMManager
from src.rag import Chatbot
from src.audio.audio_manager import AudioManager
from src.audio.stt_processor import STTProcessor
from src.audio.realtime_stt import SimpleRealtimeSTT
from src.audio.streaming_recorder import SimpleStreamingTranscriber
from src.audio.vosk_realtime import VoskRealtimeSTT
from src.vectorstore.chroma_manager import ChromaManager

# Global variables
chatbot = None
transcript_text = ""
last_summary = ""
last_topics = []
last_actions = []
last_decisions = []
current_language = "vi"
current_filename = ""
history_manager = HistoryManager()
audio_manager = AudioManager()
chroma_manager = ChromaManager()
stt_processor = None  # Lazy init (requires API key)
realtime_stt = SimpleRealtimeSTT()
streaming_transcriber = SimpleStreamingTranscriber(chunk_interval=10)  # Update every 10s
vosk_stt = VoskRealtimeSTT()  # Free, offline, realtime


def process_file(file, meeting_type, output_language):
    """Process uploaded transcript file - Using working logic from gradio_app.py."""
    global chatbot, transcript_text, last_summary, last_topics, last_actions, last_decisions, current_language, current_filename
    
    provider = "gemini"
    model = "gemini-2.5-flash"
    language = output_language
    
    upload_msg = {
        "vi": "âŒ Vui lÃ²ng upload file!",
        "en": "âŒ Please upload a file!",
        "ja": "âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼",
        "ko": "âŒ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!",
        "zh-CN": "âŒ è¯·ä¸Šä¼ æ–‡ä»¶ï¼",
        "es": "âŒ Por favor sube un archivo!",
        "fr": "âŒ Veuillez tÃ©lÃ©charger un fichier!",
        "de": "âŒ Bitte laden Sie eine Datei hoch!"
    }
    
    if file is None:
        return upload_msg.get(language, upload_msg["vi"]), "", "", "", ""
    
    current_language = language
    
    try:
        # Load transcript
        loader = TranscriptLoader()
        transcript = loader.load_file(file.name)
        
        # Clean and truncate
        preprocessor = TranscriptPreprocessor()
        transcript = preprocessor.clean_text(transcript)
        transcript = preprocessor.truncate_text(transcript, max_length=15000)
        transcript_text = transcript
        
        # Initialize LLM and chatbot
        llm_manager = LLMManager(
            provider=provider,
            model_name=model,
            temperature=Settings.TEMPERATURE,
            max_tokens=Settings.MAX_TOKENS,
            api_key=Settings.GEMINI_API_KEY,
        )
        
        chatbot = Chatbot(llm_manager=llm_manager, transcript=transcript, language=language)
        
        # Generate summary
        summary = chatbot.generate_summary()
        
        # Extract information
        topics = chatbot.extract_topics()
        action_items = chatbot.extract_action_items_initially()
        decisions = chatbot.extract_decisions()
        
        # Save results globally
        last_summary = summary
        last_topics = topics
        last_actions = action_items
        last_decisions = decisions
        current_filename = Path(file.name).name
        
        # Save to history
        try:
            history_manager.save_analysis(
                filename=file.name,
                summary=summary,
                topics=topics,
                action_items=action_items,
                decisions=decisions,
                metadata={"language": language, "meeting_type": meeting_type}
            )
        except Exception as e:
            print(f"Failed to save history: {e}")
        
        # Format outputs
        topics_text = format_topics(topics, language)
        actions_text = format_actions(action_items, language)
        decisions_text = format_decisions(decisions, language)
        
        success_msgs = {
            "vi": f"âœ… ÄÃ£ xá»­ lÃ½: {current_filename} | Loáº¡i: {meeting_type} | NgÃ´n ngá»¯: {language}",
            "en": f"âœ… Processed: {current_filename} | Type: {meeting_type} | Language: {language}",
            "ja": f"âœ… å‡¦ç†å®Œäº†: {current_filename} | ã‚¿ã‚¤ãƒ—: {meeting_type} | è¨€èª: {language}",
            "ko": f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {current_filename} | ìœ í˜•: {meeting_type} | ì–¸ì–´: {language}",
            "zh-CN": f"âœ… å·²å¤„ç†: {current_filename} | ç±»å‹: {meeting_type} | è¯­è¨€: {language}",
            "es": f"âœ… Procesado: {current_filename} | Tipo: {meeting_type} | Idioma: {language}",
            "fr": f"âœ… TraitÃ©: {current_filename} | Type: {meeting_type} | Langue: {language}",
            "de": f"âœ… Verarbeitet: {current_filename} | Typ: {meeting_type} | Sprache: {language}"
        }
        
        return (
            success_msgs.get(language, success_msgs["vi"]),
            summary,
            topics_text,
            actions_text,
            decisions_text
        )
        
    except Exception as e:
        error_prefixes = {
            "vi": "âŒ Lá»—i:",
            "en": "âŒ Error:",
            "ja": "âŒ ã‚¨ãƒ©ãƒ¼:",
            "ko": "âŒ ì˜¤ë¥˜:",
            "zh-CN": "âŒ é”™è¯¯:",
            "es": "âŒ Error:",
            "fr": "âŒ Erreur:",
            "de": "âŒ Fehler:"
        }
        return f"{error_prefixes.get(language, error_prefixes['vi'])} {str(e)}", "", "", "", ""


def format_topics(topics, language="vi"):
    """Format topics for display."""
    labels = {
        "vi": {"no_data": "_KhÃ´ng tÃ¬m tháº¥y chá»§ Ä‘á»_", "description": "MÃ´ táº£"},
        "en": {"no_data": "_No topics found_", "description": "Description"},
        "ja": {"no_data": "_ãƒˆãƒ”ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“_", "description": "èª¬æ˜"},
        "ko": {"no_data": "_ì£¼ì œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤_", "description": "ì„¤ëª…"},
        "zh-CN": {"no_data": "_æœªæ‰¾åˆ°ä¸»é¢˜_", "description": "æè¿°"},
        "es": {"no_data": "_No se encontraron temas_", "description": "DescripciÃ³n"},
        "fr": {"no_data": "_Aucun sujet trouvÃ©_", "description": "Description"},
        "de": {"no_data": "_Keine Themen gefunden_", "description": "Beschreibung"}
    }
    lang = labels.get(language, labels["vi"])
    
    if not topics:
        return lang["no_data"]
    
    result = []
    for i, topic in enumerate(topics, 1):
        result.append(f"### {i}. {topic.get('topic', 'N/A')}")
        result.append(f"{topic.get('description', '')}\n")
    
    return "\n".join(result)


def format_actions(actions, language="vi"):
    """Format action items for display."""
    labels = {
        "vi": {
            "no_data": "_KhÃ´ng cÃ³ action items_", 
            "assignee": "ğŸ‘¤ NgÆ°á»i phá»¥ trÃ¡ch", 
            "deadline": "ğŸ“… Háº¡n chÃ³t",
            "not_assigned": "ChÆ°a phÃ¢n cÃ´ng",
            "not_specified": "ChÆ°a xÃ¡c Ä‘á»‹nh"
        },
        "en": {
            "no_data": "_No action items_", 
            "assignee": "ğŸ‘¤ Assignee", 
            "deadline": "ğŸ“… Deadline",
            "not_assigned": "Not assigned",
            "not_specified": "Not specified"
        },
        "ja": {
            "no_data": "_ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ãªã—_", 
            "assignee": "ğŸ‘¤ æ‹…å½“è€…", 
            "deadline": "ğŸ“… æœŸé™",
            "not_assigned": "æœªå‰²ã‚Šå½“ã¦",
            "not_specified": "æœªæŒ‡å®š"
        },
        "ko": {
            "no_data": "_ì•¡ì…˜ ì•„ì´í…œ ì—†ìŒ_", 
            "assignee": "ğŸ‘¤ ë‹´ë‹¹ì", 
            "deadline": "ğŸ“… ë§ˆê°ì¼",
            "not_assigned": "ë¯¸í• ë‹¹",
            "not_specified": "ë¯¸ì§€ì •"
        },
        "zh-CN": {
            "no_data": "_æ— è¡ŒåŠ¨é¡¹_", 
            "assignee": "ğŸ‘¤ è´Ÿè´£äºº", 
            "deadline": "ğŸ“… æˆªæ­¢æ—¥æœŸ",
            "not_assigned": "æœªåˆ†é…",
            "not_specified": "æœªæŒ‡å®š"
        },
        "es": {
            "no_data": "_Sin elementos de acciÃ³n_", 
            "assignee": "ğŸ‘¤ Responsable", 
            "deadline": "ğŸ“… Fecha lÃ­mite",
            "not_assigned": "No asignado",
            "not_specified": "No especificado"
        },
        "fr": {
            "no_data": "_Aucun Ã©lÃ©ment d'action_", 
            "assignee": "ğŸ‘¤ Responsable", 
            "deadline": "ğŸ“… Date limite",
            "not_assigned": "Non assignÃ©",
            "not_specified": "Non spÃ©cifiÃ©"
        },
        "de": {
            "no_data": "_Keine Aktionselemente_", 
            "assignee": "ğŸ‘¤ Verantwortlich", 
            "deadline": "ğŸ“… Frist",
            "not_assigned": "Nicht zugewiesen",
            "not_specified": "Nicht angegeben"
        }
    }
    lang = labels.get(language, labels["vi"])
    
    if not actions:
        return lang["no_data"]
    
    result = []
    for i, item in enumerate(actions, 1):
        task = item.get('task', 'N/A')
        assignee = item.get('assignee', lang['not_assigned'])
        deadline = item.get('deadline', lang['not_specified'])
        
        result.append(f"### {i}. {task}")
        result.append(f"- {lang['assignee']}: **{assignee}**")
        result.append(f"- {lang['deadline']}: {deadline}\n")
    
    return "\n".join(result)


def format_decisions(decisions, language="vi"):
    """Format decisions for display."""
    labels = {
        "vi": {
            "no_data": "_KhÃ´ng cÃ³ quyáº¿t Ä‘á»‹nh_", 
            "context": "ğŸ“ Bá»‘i cáº£nh",
            "no_context": "KhÃ´ng cÃ³ bá»‘i cáº£nh"
        },
        "en": {
            "no_data": "_No decisions_", 
            "context": "ğŸ“ Context",
            "no_context": "No context"
        },
        "ja": {
            "no_data": "_æ±ºå®šãªã—_", 
            "context": "ğŸ“ æ–‡è„ˆ",
            "no_context": "æ–‡è„ˆãªã—"
        },
        "ko": {
            "no_data": "_ê²°ì • ì—†ìŒ_", 
            "context": "ğŸ“ ë§¥ë½",
            "no_context": "ë§¥ë½ ì—†ìŒ"
        },
        "zh-CN": {
            "no_data": "_æ— å†³å®š_", 
            "context": "ğŸ“ èƒŒæ™¯",
            "no_context": "æ— èƒŒæ™¯"
        },
        "es": {
            "no_data": "_Sin decisiones_", 
            "context": "ğŸ“ Contexto",
            "no_context": "Sin contexto"
        },
        "fr": {
            "no_data": "_Aucune dÃ©cision_", 
            "context": "ğŸ“ Contexte",
            "no_context": "Pas de contexte"
        },
        "de": {
            "no_data": "_Keine Entscheidungen_", 
            "context": "ğŸ“ Kontext",
            "no_context": "Kein Kontext"
        }
    }
    lang = labels.get(language, labels["vi"])
    
    if not decisions:
        return lang["no_data"]
    
    result = []
    for i, decision in enumerate(decisions, 1):
        decision_text = decision.get('decision', 'N/A')
        context = decision.get('context', lang['no_context'])
        
        result.append(f"### {i}. {decision_text}")
        result.append(f"- {lang['context']}: {context}\n")
    
    return "\n".join(result)


def chat_with_ai(message, history):
    """Chat with AI."""
    global chatbot
    
    if history is None:
        history = []
    
    if not chatbot:
        new_history = history.copy()
        new_history.append([message, "âš ï¸ Vui lÃ²ng xá»­ lÃ½ transcript trÆ°á»›c!"])
        return new_history
    
    try:
        result = chatbot.ask_question(message)
        response = result.get("answer", "Xin lá»—i, tÃ´i khÃ´ng hiá»ƒu cÃ¢u há»i.")
        
        new_history = history.copy()
        new_history.append([message, response])
        return new_history
    except Exception as e:
        new_history = history.copy()
        new_history.append([message, f"âŒ Lá»—i: {str(e)}"])
        return new_history


def export_to_txt():
    """Export analysis results to TXT file."""
    global last_summary, last_topics, last_actions, last_decisions, current_language, current_filename
    
    if not last_summary:
        return None
    
    labels = {
        "vi": {"title": "BÃO CÃO PHÃ‚N TÃCH CUá»˜C Há»ŒP", "summary": "TÃ“M Táº®T", "topics": "CHá»¦ Äá»€", "actions": "ACTION ITEMS", "decisions": "QUYáº¾T Äá»ŠNH"},
        "en": {"title": "MEETING ANALYSIS REPORT", "summary": "SUMMARY", "topics": "TOPICS", "actions": "ACTION ITEMS", "decisions": "DECISIONS"}
    }
    lang = labels.get(current_language, labels["vi"])
    
    content = []
    content.append("=" * 80)
    content.append(lang["title"].center(80))
    content.append("=" * 80)
    content.append(f"\nFile: {current_filename}")
    content.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    content.append("=" * 80)
    
    content.append(f"\n{lang['summary']}")
    content.append("-" * 80)
    content.append(last_summary)
    
    if last_topics:
        content.append(f"\n\n{lang['topics']}")
        content.append("-" * 80)
        for i, topic in enumerate(last_topics, 1):
            content.append(f"\n{i}. {topic.get('topic', 'N/A')}")
            content.append(f"   {topic.get('description', '')}")
    
    if last_actions:
        content.append(f"\n\n{lang['actions']}")
        content.append("-" * 80)
        for i, action in enumerate(last_actions, 1):
            content.append(f"\n{i}. {action.get('task', 'N/A')}")
            content.append(f"   Assignee: {action.get('assignee', 'N/A')}")
            content.append(f"   Deadline: {action.get('deadline', 'N/A')}")
    
    if last_decisions:
        content.append(f"\n\n{lang['decisions']}")
        content.append("-" * 80)
        for i, decision in enumerate(last_decisions, 1):
            content.append(f"\n{i}. {decision.get('decision', 'N/A')}")
            content.append(f"   Context: {decision.get('context', 'N/A')}")
    
    content.append("\n\n" + "=" * 80)
    
    filename = f"meeting_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    filepath = Path(filename)
    filepath.write_text("\n".join(content), encoding='utf-8')
    
    return str(filepath)


def refresh_history():
    """Refresh history dropdown."""
    history_list = history_manager.list_history(limit=20)
    
    if not history_list:
        return gr.Dropdown(choices=[], value=None), "_ChÆ°a cÃ³ lá»‹ch sá»­_"
    
    choices = [
        (f"{item['timestamp'][:10]} - {item['original_file']}", item['id'])
        for item in history_list
    ]
    
    info = f"ğŸ“Š TÃ¬m tháº¥y {len(history_list)} phÃ¢n tÃ­ch Ä‘Ã£ lÆ°u"
    
    return gr.Dropdown(choices=choices, value=None), info


def load_history(history_id):
    """Load analysis from history."""
    global last_summary, last_topics, last_actions, last_decisions, current_language
    
    if not history_id:
        return "âš ï¸ Vui lÃ²ng chá»n phÃ¢n tÃ­ch tá»« danh sÃ¡ch", "", "", "", ""
    
    data = history_manager.load_analysis(history_id)
    
    if not data:
        return "âŒ KhÃ´ng tÃ¬m tháº¥y phÃ¢n tÃ­ch", "", "", "", ""
    
    # Load data
    last_summary = data.get("summary", "")
    last_topics = data.get("topics", [])
    last_actions = data.get("action_items", [])
    last_decisions = data.get("decisions", [])
    current_language = data.get("metadata", {}).get("language", "vi")
    
    # Format outputs
    topics_text = format_topics(last_topics, current_language)
    actions_text = format_actions(last_actions, current_language)
    decisions_text = format_decisions(last_decisions, current_language)
    
    status = f"âœ… ÄÃ£ táº£i phÃ¢n tÃ­ch: {data.get('original_file')} ({data.get('timestamp')[:10]})"
    
    return status, last_summary, topics_text, actions_text, decisions_text


def toggle_recording_modal():
    """Toggle recording modal visibility."""
    return gr.Group(visible=True)


def cancel_recording():
    """Cancel recording and hide modal."""
    return gr.Group(visible=False), "_ÄÃ£ há»§y_", gr.Audio(visible=False)


def start_recording_session(title, language, auto_translate, translate_to):
    """Start recording session."""
    status = f"""
### ğŸ™ï¸ Äang ghi Ã¢m...

**TiÃªu Ä‘á»:** {title or f"Ghi Ã¢m {datetime.now().strftime('%d/%m/%Y')}"}  
**NgÃ´n ngá»¯:** {language}  
**Tá»± Ä‘á»™ng dá»‹ch:** {'CÃ³' if auto_translate else 'KhÃ´ng'}  
{f"**Dá»‹ch sang:** {translate_to}" if auto_translate else ""}

âºï¸ Äang ghi... Nháº¥n Stop khi hoÃ n thÃ nh.
    """
    return status, gr.Audio(visible=True)


def save_recording_and_transcribe(audio_file, title, language, transcript_text):
    """Save recorded audio and transcript from main recording tab."""
    if audio_file is None:
        return "âš ï¸ ChÆ°a cÃ³ audio Ä‘á»ƒ lÆ°u", ""
    
    try:
        # Save recording
        recording_id = audio_manager.save_recording(
            audio_file=audio_file,
            title=title or f"Ghi Ã¢m {datetime.now().strftime('%d/%m/%Y %H:%M')}",
            notes=f"Language: {language}"
        )
        
        # Save transcript if available
        if transcript_text and transcript_text.strip():
            transcript_file = Path(f"data/transcripts/{recording_id}.txt")
            transcript_file.parent.mkdir(parents=True, exist_ok=True)
            transcript_file.write_text(transcript_text, encoding='utf-8')
        
        status = f"""âœ… ÄÃ£ lÆ°u ghi Ã¢m vÃ  transcript!

**ID:** {recording_id}  
**Audio:** data/recordings/{recording_id}.wav
**Transcript:** data/transcripts/{recording_id}.txt

ğŸ’¡ Xem trong tab "ThÆ° Viá»‡n LÆ°u Trá»¯ > Lá»‹ch Sá»­ Ghi Ã‚m"
        """
        
        return status, recording_id
        
    except Exception as e:
        return f"âŒ Lá»—i: {str(e)}", ""


def transcribe_audio_whisper(audio_file, audio_language):
    """Transcribe audio using Whisper (local offline model).
    
    This is a generator function that yields progressive updates.
    """
    if audio_file is None or audio_file == "":
        yield "ğŸ™ï¸ Sáºµn sÃ ng ghi Ã¢m. Nháº¥n microphone icon Ä‘á»ƒ báº¯t Ä‘áº§u..."
        return
    
    try:
        import whisper
        import torch
        
        yield "ğŸ”„ Äang khá»Ÿi táº¡o Whisper (Local Offline)..."
        
        # Check if CUDA is available
        device = "cuda" if torch.cuda.is_available() else "cpu"
        yield f"âš™ï¸  Sá»­ dá»¥ng: {device.upper()}"
        
        # Load model (base model - good balance between speed and accuracy)
        yield "ğŸ“¥ Äang táº£i Whisper model (base)..."
        model = whisper.load_model("base", device=device)
        
        yield f"ğŸ¤ Äang transcribe audio (ngÃ´n ngá»¯: {audio_language})..."
        
        # Transcribe
        result = model.transcribe(
            audio_file,
            language=audio_language,
            fp16=(device == "cuda")  # Use FP16 only on GPU
        )
        
        final_transcript = result["text"].strip()
        
        # Get current date time
        from datetime import datetime
        now = datetime.now().strftime("%d/%m/%Y %H:%M")
        
        yield f"""ğŸ“ **Transcript ({audio_language}):** {now}

{final_transcript}
        """
            
    except ImportError:
        yield """âŒ Lá»—i: ChÆ°a cÃ i Ä‘áº·t Whisper

ğŸ’¡ **CÃ i Ä‘áº·t Whisper (Local Offline):**

```bash
pip install openai-whisper
```

**Hoáº·c vá»›i GPU support:**
```bash
pip install openai-whisper torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Miá»…n phÃ­, khÃ´ng cáº§n API key
- âœ… Hoáº¡t Ä‘á»™ng offline
- âœ… Há»— trá»£ 50+ ngÃ´n ngá»¯
- âœ… ChÃ­nh xÃ¡c cao

**Sau khi cÃ i, khá»Ÿi Ä‘á»™ng láº¡i á»©ng dá»¥ng.**
        """
    except Exception as e:
        error_msg = str(e)
        yield f"""âŒ Lá»—i: {error_msg}

ğŸ’¡ **HÆ°á»›ng dáº«n kháº¯c phá»¥c:**

1. CÃ i Ä‘áº·t Whisper: `pip install openai-whisper`
2. CÃ i Ä‘áº·t ffmpeg (náº¿u chÆ°a cÃ³):
   - Windows: `choco install ffmpeg`
   - Hoáº·c download: https://ffmpeg.org/download.html
3. Äáº£m báº£o file audio há»£p lá»‡ (WAV, MP3)
4. Khá»Ÿi Ä‘á»™ng láº¡i á»©ng dá»¥ng

**Chi tiáº¿t lá»—i:** {type(e).__name__}
        """


def search_recordings_ui(query):
    """Search recordings by title or notes."""
    if not query or query.strip() == "":
        return "_Nháº­p tá»« khÃ³a Ä‘á»ƒ tÃ¬m kiáº¿m_"
    
    try:
        recordings = audio_manager.get_recordings()
        query_lower = query.lower()
        
        # Filter recordings
        matches = [
            r for r in recordings
            if query_lower in r.get('title', '').lower() or
               query_lower in r.get('notes', '').lower()
        ]
        
        if not matches:
            return f"âŒ KhÃ´ng tÃ¬m tháº¥y ghi Ã¢m nÃ o vá»›i tá»« khÃ³a '{query}'"
        
        # Format results
        output = [f"# ğŸ” TÃ¬m tháº¥y {len(matches)} ghi Ã¢m\n"]
        
        for i, rec in enumerate(matches, 1):
            output.append(f"## {i}. {rec['title']}")
            output.append(f"**ID:** {rec['id']}")
            output.append(f"**NgÃ y:** {rec['timestamp'][:19]}")
            output.append(f"**Thá»i lÆ°á»£ng:** {audio_manager.format_duration(rec.get('duration'))}")
            output.append(f"**Tráº¡ng thÃ¡i:** {'âœ… ÄÃ£ xá»­ lÃ½' if rec.get('processed') else 'â³ ChÆ°a xá»­ lÃ½'}")
            if rec.get('notes'):
                output.append(f"**Ghi chÃº:** {rec['notes']}")
            output.append("\n---\n")
        
        return "\n".join(output)
        
    except Exception as e:
        return f"âŒ Lá»—i: {str(e)}"


# Semantic Search Functions
def search_meetings_ui(query, meeting_type_filter, language_filter, n_results):
    """Search meetings using semantic search."""
    if not query or query.strip() == "":
        return "âš ï¸ Vui lÃ²ng nháº­p tá»« khÃ³a tÃ¬m kiáº¿m", ""
    
    try:
        # Apply filters
        mt_filter = meeting_type_filter if meeting_type_filter != "Táº¥t cáº£" else None
        lang_filter = language_filter if language_filter != "Táº¥t cáº£" else None
        
        results = chroma_manager.semantic_search(
            query=query,
            n_results=n_results,
            meeting_type=mt_filter,
            language=lang_filter
        )
        
        if not results:
            return "âŒ KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p", ""
        
        # Format results
        markdown_output = []
        markdown_output.append(f"# ğŸ” TÃ¬m tháº¥y {len(results)} káº¿t quáº£\n")
        
        for i, result in enumerate(results, 1):
            metadata = result['metadata']
            analysis = result.get('analysis', {})
            
            markdown_output.append(f"## {i}. Meeting ID: {result['meeting_id']}")
            markdown_output.append(f"**Loáº¡i:** {metadata.get('meeting_type', 'N/A')} | "
                                  f"**NgÃ´n ngá»¯:** {metadata.get('language', 'N/A')} | "
                                  f"**NgÃ y:** {metadata.get('timestamp', 'N/A')[:10]}")
            
            # Show similarity score
            if result.get('distance') is not None:
                similarity = max(0, 100 - result['distance'] * 100)
                markdown_output.append(f"**Äá»™ tÆ°Æ¡ng Ä‘á»“ng:** {similarity:.1f}%")
            
            # Show transcript preview
            transcript_preview = result['transcript'][:300] + "..."
            markdown_output.append(f"\n**Ná»™i dung:**\n> {transcript_preview}\n")
            
            markdown_output.append("---\n")
        
        status = f"âœ… TÃ¬m tháº¥y {len(results)} meetings phÃ¹ há»£p vá»›i '{query}'"
        return status, "\n".join(markdown_output)
        
    except Exception as e:
        return f"âŒ Lá»—i: {str(e)}", ""


def get_vectordb_stats_ui():
    """Get ChromaDB statistics."""
    try:
        stats = chroma_manager.get_statistics()
        
        output = []
        output.append("# ğŸ“Š Thá»‘ng KÃª ChromaDB\n")
        output.append(f"**Tá»•ng sá»‘ meetings:** {stats['total_meetings']}\n")
        
        if stats['by_type']:
            output.append("**Theo loáº¡i:**")
            for mtype, count in stats['by_type'].items():
                output.append(f"- {mtype}: {count}")
            output.append("")
        
        if stats['by_language']:
            output.append("**Theo ngÃ´n ngá»¯:**")
            for lang, count in stats['by_language'].items():
                output.append(f"- {lang}: {count}")
        
        return "\n".join(output)
        
    except Exception as e:
        return f"âŒ Lá»—i: {str(e)}"


def get_recordings_list_ui():
    """Get list of recordings."""
    try:
        recordings = audio_manager.get_recordings()
        
        stats = audio_manager.get_statistics()
        stats_text = f"""
ğŸ“Š **Thá»‘ng KÃª Ghi Ã‚m**
- Tá»•ng sá»‘: {stats['total_recordings']}
- ÄÃ£ xá»­ lÃ½: {stats['processed']}
- ChÆ°a xá»­ lÃ½: {stats['unprocessed']}
- Tá»•ng thá»i lÆ°á»£ng: {stats['total_duration_minutes']:.1f} phÃºt
        """
        
        if not recordings:
            return gr.Dropdown(choices=[], value=None), stats_text
        
        choices = [f"{r['id']} - {r['title']}" for r in recordings]
        
        return gr.Dropdown(choices=choices, value=None), stats_text
    except Exception as e:
        print(f"Error in get_recordings_list_ui: {e}")
        return gr.Dropdown(choices=[], value=None), f"âŒ Lá»—i: {str(e)}"


def load_recording_info_ui(selected):
    """Load recording information."""
    if not selected:
        return "", "", None
    
    try:
        recording_id = selected.split(" - ")[0]
        recording = audio_manager.get_recording(recording_id)
        
        if not recording:
            return "âŒ KhÃ´ng tÃ¬m tháº¥y ghi Ã¢m", "", None
        
        info = f"""
### ğŸ“ {recording['title']}

**ID:** {recording['id']}  
**NgÃ y:** {recording['timestamp'][:19]}  
**Thá»i lÆ°á»£ng:** {audio_manager.format_duration(recording.get('duration'))}  
**Tráº¡ng thÃ¡i:** {'âœ… ÄÃ£ xá»­ lÃ½' if recording.get('processed') else 'â³ ChÆ°a xá»­ lÃ½'}  
**Ghi chÃº:** {recording.get('notes', 'KhÃ´ng cÃ³ ghi chÃº')}
        """
        
        return info, recording.get('notes', ''), recording['filepath']
    except Exception as e:
        return f"âŒ Lá»—i: {str(e)}", "", None


def delete_recording_ui(selected):
    """Delete selected recording."""
    if not selected:
        return "âš ï¸ ChÆ°a chá»n ghi Ã¢m", gr.Dropdown(choices=[], value=None), ""
    
    try:
        recording_id = selected.split(" - ")[0]
        success = audio_manager.delete_recording(recording_id)
        
        if success:
            dropdown, stats = get_recordings_list_ui()
            return f"âœ… ÄÃ£ xÃ³a {recording_id}", dropdown, stats
        else:
            return f"âŒ KhÃ´ng thá»ƒ xÃ³a {recording_id}", gr.Dropdown(choices=[], value=None), ""
    except Exception as e:
        return f"âŒ Lá»—i: {str(e)}", gr.Dropdown(choices=[], value=None), ""


def export_to_docx():
    """Export analysis results to DOCX file."""
    global last_summary, last_topics, last_actions, last_decisions, current_language, current_filename
    
    if not last_summary:
        return None
    
    try:
        from docx import Document
        from docx.shared import Pt
        from docx.enum.text import WD_ALIGN_PARAGRAPH
        
        doc = Document()
        
        # Title
        title = doc.add_heading("Meeting Analysis Report", 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        # Date
        date_para = doc.add_paragraph(f"File: {current_filename}")
        date_para.add_run(f"\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        date_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        doc.add_paragraph()
        
        # Summary
        doc.add_heading("Summary", 1)
        doc.add_paragraph(last_summary)
        
        # Topics
        if last_topics:
            doc.add_heading("Main Topics", 1)
            for i, topic in enumerate(last_topics, 1):
                p = doc.add_paragraph(style='List Number')
                p.add_run(f"{topic.get('topic', 'N/A')}").bold = True
                doc.add_paragraph(topic.get('description', ''), style='List Bullet 2')
        
        # Action Items
        if last_actions:
            doc.add_heading("Action Items", 1)
            for i, action in enumerate(last_actions, 1):
                p = doc.add_paragraph(style='List Number')
                p.add_run(f"{action.get('task', 'N/A')}").bold = True
                doc.add_paragraph(f"Assignee: {action.get('assignee', 'N/A')}", style='List Bullet 2')
                doc.add_paragraph(f"Deadline: {action.get('deadline', 'N/A')}", style='List Bullet 2')
        
        # Decisions
        if last_decisions:
            doc.add_heading("Important Decisions", 1)
            for i, decision in enumerate(last_decisions, 1):
                p = doc.add_paragraph(style='List Number')
                p.add_run(f"{decision.get('decision', 'N/A')}").bold = True
                doc.add_paragraph(f"Context: {decision.get('context', 'N/A')}", style='List Bullet 2')
        
        filename = f"meeting_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
        filepath = Path(filename)
        doc.save(str(filepath))
        
        return str(filepath)
    except Exception as e:
        print(f"Error exporting DOCX: {e}")
        return None


# Custom CSS
custom_css = """
.gradio-container {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
}

.main-header {
    text-align: center;
    padding: 2.5rem;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 12px;
    margin-bottom: 2rem;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
}

.main-header h1 {
    margin: 0;
    font-size: 2.5rem;
    font-weight: 700;
}

.main-header p {
    margin: 0.5rem 0 0 0;
    font-size: 1.1rem;
    opacity: 0.95;
}
"""

# Build UI
with gr.Blocks(css=custom_css, title="Meeting Analyzer Pro", theme=gr.themes.Soft()) as demo:
    
    # Header
    gr.HTML("""
    <div class="main-header">
        <h1>ğŸ¯ Meeting Transcript Analyzer Pro</h1>
        <p>PhÃ¢n tÃ­ch cuá»™c há»p thÃ´ng minh vá»›i AI - Há»— trá»£ Ä‘a ngÃ´n ngá»¯</p>
    </div>
    """)

    
    # Main content in tabs
    with gr.Tabs() as tabs:
        
        # Tab 1: Recording
        with gr.Tab("ğŸ™ï¸ Ghi Ã‚m"):
            with gr.Row():
                with gr.Column(scale=3):
                    with gr.Row():
                        recording_title_input = gr.Textbox(
                            label="TiÃªu Ä‘á»",
                            placeholder=f"Ghi Ã¢m {datetime.now().strftime('%d/%m/%Y')}",
                            scale=2
                        )
                        recording_lang_input = gr.Dropdown(
                            label="NgÃ´n ngá»¯",
                            choices=[("Tiáº¿ng Viá»‡t", "vi"), ("English", "en"), ("æ—¥æœ¬èª", "ja"), ("í•œêµ­ì–´", "ko"), ("ä¸­æ–‡", "zh")],
                            value="vi",
                            scale=1
                        )
                    
                    audio_recorder_main = gr.Audio(
                        sources=["microphone"],
                        type="filepath",
                        label="ğŸ™ï¸ Ghi Ã¢m",
                        waveform_options={"show_recording_waveform": True}
                    )
                    
                    transcript_display = gr.Textbox(
                        label="ğŸ“ Transcript",
                        interactive=False,
                        lines=12,
                        placeholder="Nháº¥n Stop Ä‘á»ƒ tá»± Ä‘á»™ng transcribe báº±ng OpenAI Whisper..."
                    )
                    
                    with gr.Row():
                        save_recording_btn = gr.Button("ğŸ’¾ LÆ°u Audio & Transcript", variant="primary", scale=2)
                        clear_recording_btn = gr.Button("ğŸ—‘ï¸ Há»§y", variant="secondary", scale=1)
                    
                    save_status = gr.Textbox(label="Tráº¡ng thÃ¡i", interactive=False, lines=3, show_label=False)
                    recording_id_hidden = gr.Textbox(visible=False)
                
                with gr.Column(scale=1):
                    gr.Markdown("""
                    ### ğŸ“ CÃ¡ch dÃ¹ng
                    
                    1. **Chá»n ngÃ´n ngá»¯** ghi Ã¢m
                    2. **Click microphone** â†’ Báº¯t Ä‘áº§u ghi
                    3. **Nháº¥n Stop** â†’ Tá»± Ä‘á»™ng:
                       - LÆ°u file audio
                       - Transcribe báº±ng Whisper
                    4. **Nháº¥n LÆ°u** Ä‘á»ƒ lÆ°u vÃ o thÆ° viá»‡n
                    5. **Nháº¥n Há»§y** Ä‘á»ƒ xÃ³a vÃ  ghi láº¡i
                    
                    ---
                    
                    ### âš™ï¸ CÃ´ng nghá»‡
                    
                    - **STT:** OpenAI Whisper
                    - **Äá»‹nh dáº¡ng:** WAV
                    - **Há»— trá»£:** 50+ ngÃ´n ngá»¯
                    
                    ---
                    
                    ### ğŸ’¡ LÆ°u Ã½
                    
                    - DÃ¹ng Whisper Local (Offline)
                    - Miá»…n phÃ­, khÃ´ng cáº§n API key
                    - Cáº§n cÃ i ffmpeg (xem hÆ°á»›ng dáº«n bÃªn dÆ°á»›i)
                    
                    ---
                    
                    ### ğŸ”§ CÃ i Ä‘áº·t ffmpeg
                    
                    **Windows:**
                    1. Download: [ffmpeg.org](https://ffmpeg.org/download.html)
                    2. Extract vÃ o `C:\\ffmpeg`
                    3. ThÃªm `C:\\ffmpeg\\bin` vÃ o PATH
                    4. Khá»Ÿi Ä‘á»™ng láº¡i terminal
                    
                    **Hoáº·c dÃ¹ng Chocolatey:**
                    ```
                    choco install ffmpeg
                    ```
                    """)
        
        # Tab 2: Upload & Analyze
        with gr.Tab("ğŸ“¤ Upload & PhÃ¢n TÃ­ch"):
            with gr.Row():
                with gr.Column(scale=2):
                    gr.Markdown("### ğŸ“ Upload Transcript")
                    file_input = gr.File(
                        label="Chá»n file transcript (TXT, DOCX)",
                        file_types=[".txt", ".docx"]
                    )
                    
                    with gr.Row():
                        meeting_type = gr.Dropdown(
                            label="ğŸ¯ Loáº¡i Cuá»™c Há»p",
                            choices=[
                                ("ğŸ“‹ Meeting - Cuá»™c há»p thÃ´ng thÆ°á»ng", "meeting"),
                                ("ğŸ“ Workshop - Há»™i tháº£o/ÄÃ o táº¡o", "workshop"),
                                ("ğŸ’¡ Brainstorming - Äá»™ng nÃ£o", "brainstorming")
                            ],
                            value="meeting"
                        )
                        
                        output_lang = gr.Dropdown(
                            label="ğŸŒ NgÃ´n Ngá»¯ Output",
                            choices=[
                                ("ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t", "vi"),
                                ("ğŸ‡¬ğŸ‡§ English", "en"),
                                ("ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª", "ja"),
                                ("ğŸ‡°ğŸ‡· í•œêµ­ì–´", "ko"),
                                ("ğŸ‡¨ğŸ‡³ ä¸­æ–‡", "zh-CN"),
                                ("ğŸ‡ªğŸ‡¸ EspaÃ±ol", "es"),
                                ("ğŸ‡«ğŸ‡· FranÃ§ais", "fr"),
                                ("ğŸ‡©ğŸ‡ª Deutsch", "de")
                            ],
                            value="vi"
                        )
                    
                    process_btn = gr.Button(
                        "ğŸš€ PhÃ¢n TÃ­ch Ngay",
                        variant="primary",
                        size="lg"
                    )
                    
                    status_box = gr.Textbox(
                        label="Tráº¡ng thÃ¡i",
                        interactive=False,
                        lines=2
                    )
                
                with gr.Column(scale=1):
                    gr.Markdown("""
                    ### ğŸ’¡ HÆ°á»›ng Dáº«n
                    
                    **BÆ°á»›c 1:** Upload file transcript
                    
                    **BÆ°á»›c 2:** Chá»n loáº¡i cuá»™c há»p
                    
                    **BÆ°á»›c 3:** Chá»n ngÃ´n ngá»¯ output
                    
                    **BÆ°á»›c 4:** Click "PhÃ¢n TÃ­ch Ngay"
                    
                    ---
                    
                    âœ¨ **TÃ­nh nÄƒng:**
                    - AI tá»± Ä‘á»™ng tÃ³m táº¯t
                    - TrÃ­ch xuáº¥t chá»§ Ä‘á» chÃ­nh
                    - PhÃ¡t hiá»‡n action items
                    - Ghi nháº­n quyáº¿t Ä‘á»‹nh quan trá»ng
                    - Há»— trá»£ 8 ngÃ´n ngá»¯
                    """)
            
            gr.Markdown("---")
            
            # Results section
            gr.Markdown("## ğŸ“Š Káº¿t Quáº£ PhÃ¢n TÃ­ch")
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ“ TÃ³m Táº¯t Cuá»™c Há»p")
                    summary_output = gr.Textbox(
                        lines=6,
                        interactive=False,
                        placeholder="TÃ³m táº¯t sáº½ hiá»ƒn thá»‹ á»Ÿ Ä‘Ã¢y..."
                    )
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ¯ Chá»§ Äá» ChÃ­nh")
                    topics_output = gr.Markdown("_ChÆ°a cÃ³ dá»¯ liá»‡u_")
                
                with gr.Column():
                    gr.Markdown("### âœ… Action Items")
                    actions_output = gr.Markdown("_ChÆ°a cÃ³ dá»¯ liá»‡u_")
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ¯ Quyáº¿t Äá»‹nh Quan Trá»ng")
                    decisions_output = gr.Markdown("_ChÆ°a cÃ³ dá»¯ liá»‡u_")
        
        # Tab 3: Chat with AI
        with gr.Tab("ğŸ’¬ Chat vá»›i AI"):
            gr.Markdown("### ğŸ¤– Há»i Ä‘Ã¡p thÃ´ng minh vá» cuá»™c há»p")
            
            with gr.Row():
                with gr.Column(scale=3):
                    chatbot_display = gr.Chatbot(
                        height=500,
                        label="Cuá»™c trÃ² chuyá»‡n",
                        type="tuples"
                    )
                    
                    with gr.Row():
                        chat_input = gr.Textbox(
                            placeholder="Nháº­p cÃ¢u há»i cá»§a báº¡n...",
                            show_label=False,
                            scale=4
                        )
                        send_btn = gr.Button("ğŸ“¤ Gá»­i", scale=1, variant="primary")
                    
                    clear_btn = gr.Button("ğŸ—‘ï¸ XÃ³a lá»‹ch sá»­", size="sm")
                
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ’¡ CÃ¢u Há»i Gá»£i Ã")
                    
                    q1 = gr.Button("ğŸ“‹ TÃ³m táº¯t cuá»™c há»p", size="sm")
                    q2 = gr.Button("ğŸ‘¥ Ai tham gia?", size="sm")
                    q3 = gr.Button("âœ… Action items lÃ  gÃ¬?", size="sm")
                    q4 = gr.Button("ğŸ¯ Quyáº¿t Ä‘á»‹nh quan trá»ng?", size="sm")
                    q5 = gr.Button("ğŸ“Š Chá»§ Ä‘á» chÃ­nh?", size="sm")
                    
                    gr.Markdown("""
                    ---
                    **ğŸ’¬ Báº¡n cÃ³ thá»ƒ há»i:**
                    - TÃ³m táº¯t cuá»™c há»p
                    - Ai tham gia meeting?
                    - Action items lÃ  gÃ¬?
                    - Quyáº¿t Ä‘á»‹nh nÃ o Ä‘Æ°á»£c Ä‘Æ°a ra?
                    - Chá»§ Ä‘á» chÃ­nh lÃ  gÃ¬?
                    """)
        
        # Tab 4: Library
        with gr.Tab("ğŸ“š ThÆ° Viá»‡n LÆ°u Trá»¯"):
            with gr.Tabs():
                # Sub-tab: Analysis History
                with gr.Tab("ğŸ“Š Lá»‹ch Sá»­ PhÃ¢n TÃ­ch"):
                    gr.Markdown("### ğŸ“‹ Quáº£n lÃ½ lá»‹ch sá»­ phÃ¢n tÃ­ch")
                    
                    with gr.Row():
                        history_dropdown_lib = gr.Dropdown(
                            label="Chá»n phÃ¢n tÃ­ch",
                            choices=[],
                            interactive=True,
                            scale=3
                        )
                        refresh_history_lib_btn = gr.Button("ğŸ”„ LÃ m má»›i", scale=1)
                    
                    history_info_lib = gr.Markdown("_ChÆ°a cÃ³ lá»‹ch sá»­_")
                    
                    with gr.Row():
                        with gr.Column():
                            gr.Markdown("#### ğŸ“ TÃ³m táº¯t")
                            summary_lib = gr.Textbox(lines=5, interactive=False)
                        
                        with gr.Column():
                            gr.Markdown("#### ğŸ¯ Chá»§ Ä‘á»")
                            topics_lib = gr.Markdown()
                    
                    with gr.Row():
                        load_analysis_btn = gr.Button("ğŸ“‚ Táº£i vÃ o workspace", variant="primary")
                        delete_analysis_btn = gr.Button("ğŸ—‘ï¸ XÃ³a", variant="stop")
                
                # Sub-tab: Recording History
                with gr.Tab("ğŸ™ï¸ Lá»‹ch Sá»­ Ghi Ã‚m"):
                    gr.Markdown("### ğŸ¤ Quáº£n lÃ½ ghi Ã¢m")
                    
                    with gr.Row():
                        recordings_dropdown = gr.Dropdown(
                            label="Chá»n ghi Ã¢m",
                            choices=[],
                            interactive=True,
                            scale=3
                        )
                        refresh_recordings_btn = gr.Button("ğŸ”„ LÃ m má»›i", scale=1)
                    
                    recordings_stats = gr.Markdown("ğŸ“Š ChÆ°a cÃ³ ghi Ã¢m nÃ o")
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            recording_info_display = gr.Markdown("_Chá»n ghi Ã¢m Ä‘á»ƒ xem chi tiáº¿t_")
                            recording_notes_display = gr.Textbox(label="Ghi chÃº", interactive=False, lines=3)
                        
                        with gr.Column(scale=1):
                            audio_player = gr.Audio(
                                label="PhÃ¡t láº¡i",
                                interactive=False
                            )
                            
                            with gr.Row():
                                process_recording_btn = gr.Button("ğŸ”„ Xá»­ lÃ½", variant="primary")
                                delete_recording_btn = gr.Button("ğŸ—‘ï¸ XÃ³a", variant="stop")
                            
                            delete_status = gr.Textbox(label="Tráº¡ng thÃ¡i", interactive=False)
        
        # Tab 5: Semantic Search
        with gr.Tab("ğŸ” TÃ¬m Kiáº¿m ThÃ´ng Minh"):
            with gr.Tabs():
                # Sub-tab: Search Analysis
                with gr.Tab("ğŸ“Š TÃ¬m PhÃ¢n TÃ­ch"):
                    gr.Markdown("### ğŸ” TÃ¬m kiáº¿m lá»‹ch sá»­ phÃ¢n tÃ­ch")
                    
                    # Statistics
                    with gr.Accordion("ğŸ“Š Thá»‘ng KÃª Database", open=False):
                        stats_display = gr.Markdown()
                        refresh_stats_btn = gr.Button("ğŸ”„ LÃ m má»›i thá»‘ng kÃª")
                    
                    # Search interface
                    with gr.Row():
                        with gr.Column(scale=3):
                            search_query = gr.Textbox(
                                label="TÃ¬m kiáº¿m",
                                placeholder="VD: React Hooks training, budget planning, team meeting...",
                                lines=2
                            )
                        with gr.Column(scale=1):
                            meeting_type_filter = gr.Dropdown(
                                label="Loáº¡i Meeting",
                                choices=["Táº¥t cáº£", "meeting", "workshop", "brainstorming"],
                                value="Táº¥t cáº£"
                            )
                            language_filter = gr.Dropdown(
                                label="NgÃ´n ngá»¯",
                                choices=["Táº¥t cáº£", "en", "vi", "ja", "ko", "zh-CN"],
                                value="Táº¥t cáº£"
                            )
                            n_results = gr.Slider(
                                label="Sá»‘ káº¿t quáº£",
                                minimum=1,
                                maximum=10,
                                value=5,
                                step=1
                            )
                    
                    search_btn = gr.Button("ğŸ” TÃ¬m kiáº¿m", variant="primary", size="lg")
                    search_status = gr.Textbox(label="Tráº¡ng thÃ¡i", interactive=False)
                    search_results = gr.Markdown()
                    
                    # Examples
                    gr.Examples(
                        examples=[
                            ["React Hooks training", "workshop", "en", 3],
                            ["budget planning meeting", "meeting", "Táº¥t cáº£", 5],
                            ["brainstorming new features", "brainstorming", "Táº¥t cáº£", 3],
                        ],
                        inputs=[search_query, meeting_type_filter, language_filter, n_results]
                    )
                
                # Sub-tab: Search Recordings
                with gr.Tab("ğŸ™ï¸ TÃ¬m Ghi Ã‚m"):
                    gr.Markdown("### ğŸ” TÃ¬m kiáº¿m ghi Ã¢m cuá»™c gá»i")
                    
                    with gr.Row():
                        search_recording_query = gr.Textbox(
                            label="TÃ¬m kiáº¿m theo tiÃªu Ä‘á» hoáº·c ghi chÃº",
                            placeholder="VD: Team meeting, Sprint planning...",
                            scale=3
                        )
                        search_recording_btn = gr.Button("ğŸ” TÃ¬m", variant="primary", scale=1)
                    
                    search_recording_results = gr.Markdown("_Nháº­p tá»« khÃ³a Ä‘á»ƒ tÃ¬m kiáº¿m_")
                    
                    gr.Markdown("""
                    ---
                    **ğŸ’¡ Máº¹o tÃ¬m kiáº¿m:**
                    - TÃ¬m theo tiÃªu Ä‘á»: "Team meeting"
                    - TÃ¬m theo ngÃ y: "25/11/2024"
                    - TÃ¬m theo ghi chÃº: "Sprint planning"
                    """)
        
        # Tab 6: Export Results
        with gr.Tab("ğŸ“„ Xuáº¥t Káº¿t Quáº£"):
            gr.Markdown("### ğŸ“¥ Táº£i xuá»‘ng káº¿t quáº£ phÃ¢n tÃ­ch")
            
            with gr.Row():
                with gr.Column():
                    gr.Markdown("""
                    #### ğŸ“„ Xuáº¥t file TXT
                    - Format Ä‘Æ¡n giáº£n, dá»… Ä‘á»c
                    - PhÃ¹ há»£p Ä‘á»ƒ chia sáº» qua email
                    - Má»Ÿ Ä‘Æ°á»£c trÃªn má»i thiáº¿t bá»‹
                    """)
                    export_txt_btn = gr.Button("ğŸ“„ Xuáº¥t TXT", size="lg", variant="primary")
                
                with gr.Column():
                    gr.Markdown("""
                    #### ğŸ“ Xuáº¥t file DOCX
                    - Format chuyÃªn nghiá»‡p
                    - CÃ³ thá»ƒ chá»‰nh sá»­a trong Word
                    - PhÃ¹ há»£p cho bÃ¡o cÃ¡o
                    """)
                    export_docx_btn = gr.Button("ğŸ“ Xuáº¥t DOCX", size="lg", variant="primary")
            
            export_file = gr.File(label="File Ä‘Ã£ xuáº¥t")
            
            gr.Markdown("""
            ---
            **ğŸ’¡ LÆ°u Ã½:**
            - Cáº§n xá»­ lÃ½ transcript trÆ°á»›c khi xuáº¥t
            - File sáº½ Ä‘Æ°á»£c lÆ°u vá»›i timestamp
            - Há»— trá»£ Ä‘a ngÃ´n ngá»¯
            """)
    
    # Footer
    gr.Markdown("""
    ---
    <div style="text-align: center; color: #666; padding: 1rem;">
        <p>ğŸš€ Powered by Gemini AI | ï¿½ï¸ Audio aRecording | ğŸ” Semantic Search | ğŸŒ Multi-language</p>
        <p style="font-size: 0.9em;">Version 3.1 - Sprint 3 Complete Edition</p>
    </div>
    """)
    
    # Event handlers
    
    # Recording Tab handlers
    
    # Auto-transcribe when recording stops (audio changes)
    audio_recorder_main.stop_recording(
        fn=transcribe_audio_whisper,
        inputs=[audio_recorder_main, recording_lang_input],
        outputs=[transcript_display]
    )
    
    save_recording_btn.click(
        fn=save_recording_and_transcribe,
        inputs=[audio_recorder_main, recording_title_input, recording_lang_input, transcript_display],
        outputs=[save_status, recording_id_hidden]
    )
    
    clear_recording_btn.click(
        fn=lambda: (None, "", "", ""),
        outputs=[audio_recorder_main, transcript_display, save_status, recording_id_hidden]
    )
    
    # Library - Analysis History handlers
    refresh_history_lib_btn.click(
        fn=refresh_history,
        outputs=[history_dropdown_lib, history_info_lib]
    )
    
    load_analysis_btn.click(
        fn=load_history,
        inputs=[history_dropdown_lib],
        outputs=[status_box, summary_output, topics_output, actions_output, decisions_output]
    )
    
    # Auto-refresh on page load
    demo.load(
        fn=get_vectordb_stats_ui,
        outputs=[stats_display]
    ).then(
        fn=get_recordings_list_ui,
        outputs=[recordings_dropdown, recordings_stats]
    ).then(
        fn=refresh_history,
        outputs=[history_dropdown_lib, history_info_lib]
    )
    
    # Process handler
    process_btn.click(
        fn=process_file,
        inputs=[file_input, meeting_type, output_lang],
        outputs=[status_box, summary_output, topics_output, actions_output, decisions_output]
    ).then(
        fn=refresh_history,  # Refresh history after processing
        outputs=[history_dropdown_lib, history_info_lib]
    )
    
    # Export handlers
    export_txt_btn.click(
        fn=export_to_txt,
        outputs=[export_file]
    )
    
    export_docx_btn.click(
        fn=export_to_docx,
        outputs=[export_file]
    )
    
    # Recording Library handlers
    refresh_recordings_btn.click(
        fn=get_recordings_list_ui,
        outputs=[recordings_dropdown, recordings_stats]
    )
    
    recordings_dropdown.change(
        fn=load_recording_info_ui,
        inputs=[recordings_dropdown],
        outputs=[recording_info_display, recording_notes_display, audio_player]
    )
    
    delete_recording_btn.click(
        fn=delete_recording_ui,
        inputs=[recordings_dropdown],
        outputs=[delete_status, recordings_dropdown, recordings_stats]
    )
    
    # Semantic Search handlers
    refresh_stats_btn.click(
        fn=get_vectordb_stats_ui,
        outputs=[stats_display]
    )
    
    search_btn.click(
        fn=search_meetings_ui,
        inputs=[search_query, meeting_type_filter, language_filter, n_results],
        outputs=[search_status, search_results]
    )
    
    search_recording_btn.click(
        fn=search_recordings_ui,
        inputs=[search_recording_query],
        outputs=[search_recording_results]
    )
    
    # Chat handlers
    send_btn.click(
        fn=chat_with_ai,
        inputs=[chat_input, chatbot_display],
        outputs=[chatbot_display]
    ).then(
        fn=lambda: "",
        outputs=[chat_input]
    )
    
    chat_input.submit(
        fn=chat_with_ai,
        inputs=[chat_input, chatbot_display],
        outputs=[chatbot_display]
    ).then(
        fn=lambda: "",
        outputs=[chat_input]
    )
    
    clear_btn.click(
        fn=lambda: [],
        outputs=[chatbot_display]
    )
    
    # Quick questions
    def send_q(q, h):
        if h is None:
            h = []
        return chat_with_ai(q, h)
    
    q1.click(fn=lambda h: send_q("TÃ³m táº¯t cuá»™c há»p nÃ y", h), inputs=[chatbot_display], outputs=[chatbot_display])
    q2.click(fn=lambda h: send_q("Ai tham gia cuá»™c há»p?", h), inputs=[chatbot_display], outputs=[chatbot_display])
    q3.click(fn=lambda h: send_q("Action items lÃ  gÃ¬?", h), inputs=[chatbot_display], outputs=[chatbot_display])
    q4.click(fn=lambda h: send_q("Nhá»¯ng quyáº¿t Ä‘á»‹nh quan trá»ng nÃ o Ä‘Æ°á»£c Ä‘Æ°a ra?", h), inputs=[chatbot_display], outputs=[chatbot_display])
    q5.click(fn=lambda h: send_q("Chá»§ Ä‘á» chÃ­nh cá»§a cuá»™c há»p lÃ  gÃ¬?", h), inputs=[chatbot_display], outputs=[chatbot_display])


if __name__ == "__main__":
    demo.launch(
        server_name="localhost",
        server_port=7777,
        share=False
    )
