# ğŸš€ Sprint Planning - Meeting Transcript Chatbot

Dá»± Ã¡n Ä‘Æ°á»£c chia thÃ nh 4 sprints tÆ°Æ¡ng á»©ng vá»›i 4 workshop trong khÃ³a há»c AI Engineering.

---

## ğŸ“‹ Sprint Overview

| Sprint | Session | Workshop | CÃ´ng nghá»‡ chÃ­nh | Branch | Timeline | Status |
|--------|---------|----------|-----------------|--------|----------|--------|
| Sprint 1 | Session 1 | Workshop 1 (6h) | Python & OpenAI API | `sprint-1` | Nov 16 | ğŸ”„ 60% Complete |
| Sprint 2 | Session 2 | Workshop 2 (8h) | OpenAI API & Llama 3 | `sprint-2` | Nov 23 | ğŸ“… Planned |
| Sprint 3 | Session 3 | Workshop 3 (6h) | ChromaDB & HuggingFace TTS | `sprint-3` | Nov 30 | ğŸ“… Planned |
| Sprint 4 | Session 4 | Workshop 4 (1h) | LangChain & RAG | `sprint-4` | Dec 7 | ğŸ“… Planned |

---

## Sprint 1: Python & OpenAI API Basics
**Session 1 - Python & OpenAI API**  
**Workshop 1 - Building Real-World AI-Powered Apps Using Python and OpenAI API**

**ï¿½  Timeline**: November 10-14, 2025 (5 days)  
**ï¿½ Woorkshop**: Saturday, Nov 15 (1.5 hours)  
**ğŸ‘¥ Team**: 7 members  
**ğŸ“Š Progress**: 60% Complete

### ğŸ¯ Learning Objectives (tá»« khÃ³a há»c)
**Python Fundamentals:**
- Comments, Calculations, Data types
- Variables, Lists, Dictionaries, Sets, Tuples
- Comparison operators, Conditional statements
- For loops, While loops

**OpenAI API:**
- OpenAI models overview
- API authentication & basics
- Sending requests in Python
- Handling responses
- Text generation & Prompt design
- Chat completions
- Real-world use cases

### ğŸ¯ Project Goals
- Thiáº¿t láº­p mÃ´i trÆ°á»ng Python cÆ¡ báº£n
- TÃ­ch há»£p OpenAI/Gemini API
- XÃ¢y dá»±ng Meeting Summarizer chatbot
- Prompt engineering cho extraction tasks
- Táº¡o giao diá»‡n Gradio

### âœ… Deliverables
- [x] Cáº¥u hÃ¬nh project vá»›i virtual environment
- [x] TÃ­ch há»£p Gemini API (tÆ°Æ¡ng Ä‘Æ°Æ¡ng OpenAI)
- [x] XÃ¢y dá»±ng module xá»­ lÃ½ transcript
- [x] Prompt templates cho summary/extraction
- [x] Táº¡o UI Gradio Ä‘Æ¡n giáº£n
- [ ] Unit tests cÆ¡ báº£n
- [ ] Complete Assignment 03 equivalent

### ğŸ“ Related Assignments (Reference)
- Assignment 01: Command-Line Task Manager (Python basics)
- Assignment 02: Automotive Prompt-Driven Agent
- **Assignment 03: AI-Powered Meeting Summarizer** â­ (Our project!)

### ğŸ“ Assessment
- Quiz 01: Python & OpenAI (15 mins)
- Mock Interview 1: Python & OpenAI concepts (10-15 mins)

### ğŸ› ï¸ Tech Stack
- Python 3.11+
- Google Gemini API
- Gradio
- python-docx

### ğŸ“‚ Code Structure
```
src/
â”œâ”€â”€ config/settings.py      # API configuration
â”œâ”€â”€ llm/chat_model.py       # Gemini integration
â”œâ”€â”€ llm/prompts.py          # Prompt templates
â”œâ”€â”€ data/loader.py          # File loading
â”œâ”€â”€ data/preprocessor.py    # Text preprocessing
â””â”€â”€ ui/gradio_app.py        # Gradio interface
```

### ğŸ”— Branch
```bash
git checkout sprint-1
```

### ğŸ‘¥ Team Assignments
See detailed task breakdown: [TEAM_TASKS.md](TEAM_TASKS.md)

---

## Sprint 2: Advanced LLM Integration
**Session 2 - OpenAI API & Llama 3**  
**Workshop 2 - Building Chatbot Systems Using Azure OpenAI API**

**ğŸ“… Preparation**: November 17-22, 2025 (6 days)  
**ğŸ“… Workshop Day**: Saturday, Nov 23, 2025 (8 hours) - Virtual via MS Teams  
**ğŸ‘¥ Team**: 7 members (5 active participants during workshop)

### ğŸ¯ Learning Objectives (tá»« khÃ³a há»c)
**Developing AI Systems with OpenAI:**
- Best practices for OpenAI API
- Moderation & Validation
- Testing & Safety practices
- Function calling
- Connecting external systems and APIs
- Production-ready application design

**Llama 3:**
- Llama 3 setup
- Running Llama locally
- Prompt adjustment
- Contextual conversations
- Output adaptation
- Structured data generation
- Response refinement

### ğŸ¯ Workshop 2 Requirements (IMPORTANT!)
**Coverage**: Multi-turn chatbot systems with advanced features

**Deliverables by end of workshop:**
1. âœ… **Real-world problem definition** + mock data schema
2. âœ… **Prompt templates** using few-shot & chain-of-thought techniques
3. âœ… **Complete OpenAI SDK chatbot** implementing:
   - Chat completion
   - Function calling
   - Batching
   - Message management (conversation history)
4. âœ… **Tested conversation logs** showing multi-turn dialogue with context
5. âœ… **Team presentation** with demo, insights, lessons learned

**Key Features to Implement:**
- ğŸ”„ Multi-turn conversation with context retention
- ğŸ› ï¸ Function calling for external data/APIs
- ğŸ“¦ Batching for efficient API usage
- ğŸ’¬ Conversation message management
- ğŸ¯ Few-shot prompting examples
- ğŸ§  Chain-of-thought reasoning
- ğŸ“Š Mock data generation and usage

### ğŸ¯ Project Goals for Sprint 2

**Pre-Workshop Preparation (Nov 17-22):**
- Setup OpenAI SDK and Azure credentials
- Study OpenAI API documentation
- Prepare conversation management framework
- Create function calling templates
- Prepare mock data examples
- Setup demo environment

**Workshop Day (Nov 23 - 8 hours):**
- Hour 1-2: Problem definition & design
- Hour 3-4: Prompt engineering & setup
- Hour 5-6: Core implementation (chat + conversation)
- Hour 7: Function calling implementation
- Hour 8: Testing & presentation

### ğŸ“‹ Key Tasks

**Pre-Workshop (Nov 17-22)**:
- [ ] Setup OpenAI SDK & credentials
- [ ] Study OpenAI documentation
- [ ] Prepare conversation framework
- [ ] Create function calling templates
- [ ] Prepare mock data & scenarios

**Workshop Day (Nov 23 - 8 hours)**:
- [ ] Define problem & mock data
- [ ] Design prompt templates
- [ ] Implement chat completion
- [ ] Add conversation management
- [ ] Implement function calling
- [ ] Test & document
- [ ] Team presentation

### ğŸ“ Related Assignments (Reference)
- **Assignment 04**: Efficient API Usage with Function Calling & Batching â­
- **Assignment 05**: Resume Generation Using LLaMA3
- **Assignment 06**: Logistics Delay Classification

### ğŸ“ Assessment
- Quiz 02: OpenAI API & Llama3 (15 mins)
- Mock Interview 2: Advanced API concepts (10-15 mins)
- **Workshop 2**: Team presentation with working demo



### ğŸ› ï¸ Tech Stack
- OpenAI API (GPT-3.5/4)
- Llama 3 (Ollama hoáº·c Groq API)
- Google Gemini API
- Gradio vá»›i chat interface

### ğŸ“‚ New Modules
```
src/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ base.py             # Abstract LLM class
â”‚   â”œâ”€â”€ openai_model.py     # OpenAI integration
â”‚   â”œâ”€â”€ llama_model.py      # Llama 3 integration
â”‚   â””â”€â”€ gemini_model.py     # Gemini integration
â””â”€â”€ memory/
    â””â”€â”€ conversation.py     # Chat history management
```

### ğŸ”— Branch
```bash
git checkout sprint-2
```

---

## Sprint 3: Embeddings & Semantic Search
**Session 3 - Hugging Face & Embeddings with OpenAI**  
**Workshop 3 - Building a Text-to-Speech Chatbot Using OpenAI SDK + Hugging Face TTS**

**ğŸ“… Timeline**: November 24-28, 2025 (5 days)  
**ğŸ“… Workshop**: Saturday, Nov 29 (1.5 hours)  
**ğŸ‘¥ Team**: 7 members

### ğŸ¯ Learning Objectives (tá»« khÃ³a há»c)
**Hugging Face:**
- Hugging Face Hub
- Model selection & Dataset selection
- Hugging Face API
- Model search by task/author/popularity
- Pipelines
- Text classification & summarization
- Document-based conversation

**Embeddings:**
- Text embeddings
- Semantic meaning encoding
- OpenAI Embeddings API
- Creating embeddings from text
- Semantic search
- Recommendation engines
- Vector databases
- Storing & querying embeddings
- Production-ready applications

### ğŸ¯ Project Goals
- TÃ­ch há»£p Hugging Face models
- Implement embeddings cho transcript
- XÃ¢y dá»±ng semantic search
- Custom RAG pipeline (no frameworks)
- Cáº£i thiá»‡n context retrieval

### ğŸ“‹ Tasks
- [ ] TÃ­ch há»£p Hugging Face Transformers
- [ ] Setup sentence-transformers (e.g., all-MiniLM-L6-v2)
- [ ] Implement text chunking strategies
- [ ] Táº¡o embeddings cho transcript chunks
- [ ] Build in-memory vector store (NumPy arrays)
- [ ] Implement cosine similarity search
- [ ] XÃ¢y dá»±ng context retrieval & ranking
- [ ] ThÃªm semantic search UI
- [ ] Optimize embedding performance
- [ ] Compare semantic vs keyword search

### ğŸ“ Related Assignments (Reference)
- Assignment 07: Clone & Inference with HF Text-to-Speech
- Assignment 08: Semantic Search Engine for Clothing Products
- Assignment 09: Laptop Consultant Chatbot

### ğŸ“ Assessment
- Quiz 03: Hugging Face & Embeddings (15 mins)
- Mock Interview 3: Embeddings concepts (10-15 mins)

### ğŸ› ï¸ Tech Stack
- Hugging Face Transformers
- sentence-transformers (e.g., all-MiniLM-L6-v2)
- NumPy (vector operations)
- **NO LangChain** - tá»± build Ä‘á»ƒ hiá»ƒu!
- **NO Pinecone** - dÃ¹ng in-memory store

### ğŸ¯ Key Learning Points
- Hiá»ƒu embeddings lÃ  gÃ¬ vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng
- Tá»± implement vector similarity
- Document chunking strategies
- Trade-offs: accuracy vs speed vs memory

### ğŸ“‚ New Modules
```
src/
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ encoder.py          # Text to embeddings
â”‚   â””â”€â”€ similarity.py       # Similarity calculations
â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ chunker.py          # Text chunking
â”‚   â””â”€â”€ searcher.py         # Semantic search
â””â”€â”€ vectorstore/
    â””â”€â”€ memory_store.py     # In-memory vector storage
```

### ğŸ”— Branch
```bash
git checkout sprint-3
```

---

## Sprint 4: RAG with Vector Database
**Session 4 - Pinecone & LangChain**  
**Workshop 4 - Building Chatbot RAG Systems with Vector Store, LangChain & Function Calling**

**ğŸ“… Timeline**: December 1-5, 2025 (5 days)  
**ğŸ“… Workshop**: Saturday, Dec 6 (1.5 hours)  
**ğŸ‘¥ Team**: 7 members

### ğŸ¯ Learning Objectives (tá»« khÃ³a há»c)
**Pinecone:**
- Vector ingestion & manipulation
- Vector querying
- Pinecone indexes
- Retrieval Augmented Generation (RAG)
- Semantic search
- Context-aware chatbots
- Database performance tuning
- Storage optimization
- Query latency optimization

**LangChain:**
- LangChain overview
- LLM integration
- Data source integration
- Prompt management
- Application workflow design
- Multi-provider integration
- Building dynamic applications
- Intelligent application development

### ğŸ¯ Project Goals
- TÃ­ch há»£p Pinecone vector database
- Migrate tá»« custom RAG sang LangChain
- Production-ready RAG system
- Advanced retrieval strategies
- Monitoring & optimization

### ğŸ“‹ Tasks
- [ ] Setup Pinecone database & indexes
- [ ] Migrate embeddings to Pinecone
- [ ] Implement LangChain RAG pipeline
- [ ] Compare performance: Custom (Sprint 3) vs LangChain
- [ ] Advanced retrieval strategies (MMR, reranking)
- [ ] Add citation/source tracking
- [ ] Implement caching layer
- [ ] Add monitoring & logging (LangSmith)
- [ ] Function calling integration
- [ ] Cost optimization
- [ ] Production deployment guide

### ğŸ“ Related Assignments (Reference)
- Assignment 10: Using Pinecone to Retrieve Top 3 Similar Products
- Assignment 11: Build AI Agent for Weather & Search Queries
- Assignment 12: Aviation Satellite Image Cloud Detection

### ğŸ“ Assessment
- Quiz 04: Pinecone & LangChain (15 mins)
- Mock Interview 4: Vector DB & RAG concepts (10-15 mins)

### ğŸ› ï¸ Tech Stack
- **LangChain** - RAG framework
- **Pinecone** - Managed vector database
- **LangSmith** - Monitoring & debugging
- Keep custom RAG code for comparison

### ğŸ¯ Key Learning Points
- Khi nÃ o nÃªn dÃ¹ng framework vs tá»± build
- Trade-offs: flexibility vs speed of development
- Production considerations: scaling, monitoring, costs
- Best practices tá»« LangChain ecosystem

### ğŸ“Š Comparison Matrix
| Feature | Custom (Sprint 3) | LangChain (Sprint 4) |
|---------|-------------------|----------------------|
| Setup time | Longer | Faster |
| Control | Full | Limited |
| Maintenance | More code | Less code |
| Debugging | Easier (you wrote it) | Harder (black box) |
| Features | Custom | Rich ecosystem |
| Production | DIY | Built-in patterns |

### ğŸ“‚ New Modules
```
src/
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ pinecone_store.py   # Pinecone integration
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ pipeline.py         # RAG pipeline
â”‚   â”œâ”€â”€ retriever.py        # Advanced retrieval
â”‚   â””â”€â”€ chain.py            # LangChain chains
â””â”€â”€ monitoring/
    â””â”€â”€ logger.py           # Logging & metrics
```

### ğŸ”— Branch
```bash
git checkout sprint-4
```

---

## Sprint 5: Advanced RAG & LangGraph
**Session 5 - RAG & LangGraph**  
**Hackathon - Building Advanced AI Applications**

**ğŸ“… Preparation**: December 8-12, 2025 (5 days)  
**ğŸ“… Hackathon**: Saturday, Dec 13, 2025 (8 hours)  
**ğŸ‘¥ Team**: 7 members

### ğŸ¯ Learning Objectives
**RAG with LangChain:**
- RAG fundamentals & patterns
- External data integration
- Vector databases (Pinecone, FAISS)
- LLM integration (GPT-4o-Mini)
- Graph RAG with knowledge graphs

**LangGraph & Agentic Systems:**
- Stateful graph execution
- Node branching & tool use
- Async flow management
- Multi-agent coordination
- Complex task automation

### ğŸ¯ Hackathon Goals (8 hours)
Build production-ready AI application with:
- Advanced RAG implementation
- LangGraph workflows
- Multi-agent systems (optional)
- Real-world problem solving

### ğŸ“‹ Key Tasks

**Pre-Hackathon (Dec 8-12)**:
- [ ] Study RAG & LangGraph concepts
- [ ] Review LangChain documentation
- [ ] Prepare project ideas
- [ ] Setup development environment
- [ ] Form team & assign roles

**Hackathon Day (Dec 13 - 8 hours)**:
- [ ] Define problem & architecture
- [ ] Implement RAG pipeline
- [ ] Build LangGraph workflows
- [ ] Integrate tools & agents
- [ ] Test & optimize
- [ ] Prepare presentation
- [ ] Demo & Q&A

### ğŸ“ Related Assignments
- Assignment 13: Patient Information Chatbot Agent
- Assignment 14: Retail RAG Chatbot

### ğŸ“ Assessment
- Quiz 05: RAG & LangGraph (15 mins)
- Final Mock Interview: All concepts (30 mins)
- **Hackathon**: 8 hours project
- Post-Assessment: 70 mins

### ğŸ”— Branch
```bash
git checkout sprint-5
```

---

## ğŸ”„ Sprint Workflow

### Báº¯t Ä‘áº§u Sprint má»›i
```bash
# Checkout sprint branch
git checkout -b sprint-X

# CÃ i Ä‘áº·t dependencies má»›i (náº¿u cÃ³)
pip install -r requirements.txt

# Cháº¡y tests
pytest tests/
```

### Káº¿t thÃºc Sprint
```bash
# Commit changes
git add .
git commit -m "feat(sprint-X): complete sprint X deliverables"

# Merge vÃ o main
git checkout main
git merge sprint-X

# Push lÃªn GitHub
git push origin main
git push origin sprint-X
```

---

## ğŸ“Š Progress Tracking

### Sprint 1: ğŸ”„ 60% Complete (Nov 10-14)
**Status**: IN PROGRESS - Day 1/5

**Completed** âœ…:
- [x] Project setup & configuration
- [x] Gemini API integration
- [x] Basic chatbot logic
- [x] Gradio UI foundation
- [x] Export functionality (TXT/DOCX)
- [x] Prompt templates (5 languages)

**In Progress** ğŸ”„:
- [ ] Error handling & validation
- [ ] Response optimization
- [ ] JSON parsing improvements
- [ ] UI/UX enhancements

**Remaining** ğŸ“‹:
- [ ] Unit tests (>80% coverage)
- [ ] Integration tests
- [ ] Documentation completion
- [ ] Demo preparation
- [ ] Quiz 01 & Mock Interview 1

**Blockers**: None  
**Next Milestone**: Complete IN PROGRESS tasks by Nov 11

---

### Sprint 2: ğŸ“… Not Started (Nov 17-21)
**Status**: PLANNED

**Key Tasks**:
- [ ] Abstract LLM interface
- [ ] OpenAI API integration
- [ ] Llama 3 integration (Ollama/Groq)
- [ ] Function calling
- [ ] Conversation memory
- [ ] Batching & retry mechanisms
- [ ] Streaming responses

**Dependencies**: Sprint 1 completion  
**Preparation**: Review OpenAI & Llama 3 docs

---

### Sprint 3: ğŸ“… Not Started (Nov 24-28)
**Status**: PLANNED

**Key Tasks**:
- [ ] Hugging Face setup
- [ ] Sentence transformers integration
- [ ] Text chunking strategies
- [ ] In-memory vector store (NumPy)
- [ ] Cosine similarity search
- [ ] Context retrieval & ranking
- [ ] Semantic search UI
- [ ] **Build everything from scratch!**

**Dependencies**: Sprint 2 completion  
**Preparation**: Study embeddings concepts

---

### Sprint 4: ğŸ“… Not Started (Dec 1-5)
**Status**: PLANNED

**Key Tasks**:
- [ ] Pinecone setup & indexes
- [ ] Migrate to Pinecone
- [ ] LangChain RAG pipeline
- [ ] Performance comparison (Custom vs LangChain)
- [ ] Advanced retrieval (MMR, reranking)
- [ ] Citation tracking
- [ ] Monitoring (LangSmith)
- [ ] Production deployment

**Dependencies**: Sprint 3 completion  
**Preparation**: Setup Pinecone account, study LangChain

---

### Sprint 5: ğŸ“… Not Started (Dec 8-12)
**Status**: PLANNED

**Key Tasks**:
- [ ] Advanced RAG patterns
- [ ] Graph RAG implementation
- [ ] LangGraph workflows
- [ ] Multi-agent systems
- [ ] Agentic tool integration
- [ ] Hackathon project
- [ ] Final optimization
- [ ] Final assessment prep

**Dependencies**: Sprint 4 completion  
**Preparation**: Study LangGraph & agentic systems

---

## ğŸ“Š Overall Project Progress

| Sprint | Timeline | Status | Progress | Key Deliverable |
|--------|----------|--------|----------|-----------------|
| Sprint 1 | Nov 10-14 | ğŸ”„ Active | 60% | Meeting Summarizer |
| Sprint 2 | Nov 17-21 | ğŸ“… Planned | 0% | Multi-LLM System |
| Sprint 3 | Nov 24-28 | ğŸ“… Planned | 0% | Custom RAG |
| Sprint 4 | Dec 1-5 | ğŸ“… Planned | 0% | LangChain RAG |
| Sprint 5 | Dec 8-12 | ğŸ“… Planned | 0% | Agentic System |
| **TOTAL** | **5 weeks** | | **12%** | **Production AI App** |

**Last Updated**: November 10, 2025  
**Current Focus**: Sprint 1 - Foundation  
**Next Milestone**: Sprint 1 completion (Nov 14)

---

## ğŸ“ Learning Philosophy & Outcomes

### ğŸ“š Progressive Learning Approach

**Phase 1: Foundation (Sprint 1-2)**
- âœ‹ **Build from scratch** - KhÃ´ng dÃ¹ng frameworks phá»©c táº¡p
- ğŸ¯ **Goal**: Hiá»ƒu core concepts cá»§a LLM applications
- ğŸ› ï¸ **Tools**: Pure Python, API clients, Gradio

**Phase 2: Advanced Concepts (Sprint 3)**
- ğŸ”¨ **Custom RAG** - Tá»± implement retrieval system
- ğŸ¯ **Goal**: Hiá»ƒu embeddings, vector search, semantic retrieval
- ğŸ› ï¸ **Tools**: Hugging Face, NumPy, custom vector store

**Phase 3: Production Ready (Sprint 4)**
- ğŸš€ **Frameworks & Services** - LangChain, Pinecone
- ğŸ¯ **Goal**: So sÃ¡nh approaches, production deployment
- ğŸ› ï¸ **Tools**: LangChain, Pinecone, monitoring tools

### ğŸ’¡ Why This Approach?
âœ… Hiá»ƒu sÃ¢u internal workings trÆ°á»›c khi dÃ¹ng frameworks  
âœ… Debug & troubleshoot hiá»‡u quáº£ hÆ¡n  
âœ… Biáº¿t khi nÃ o nÃªn tá»± build vs dÃ¹ng framework  
âœ… Tá»± tin customize cho use cases Ä‘áº·c biá»‡t  

---

## ğŸ¯ Learning Outcomes by Sprint

### Sprint 1: LLM Basics
**Skills:**
- Python environment & dependency management
- API integration (OpenAI/Gemini)
- Prompt engineering fundamentals
- Basic UI with Gradio
- Error handling & validation

**Deliverables:**
- Working chatbot vá»›i 1 LLM provider
- Clean code structure
- Basic tests

---

### Sprint 2: Multi-LLM Architecture
**Skills:**
- Abstract interfaces & polymorphism
- Multi-provider architecture
- Conversation state management
- Streaming responses
- Advanced prompt techniques

**Deliverables:**
- Support 3+ LLM providers
- Conversation memory
- Improved UX vá»›i streaming

---

### Sprint 3: RAG from Scratch
**Skills:**
- Text embeddings & vector representations
- Cosine similarity & semantic search
- Document chunking strategies
- Context retrieval & ranking
- Performance optimization

**Deliverables:**
- Custom RAG pipeline
- Semantic search functionality
- Efficient vector operations
- **NO LangChain/Pinecone yet** - tá»± build Ä‘á»ƒ há»c!

**Key Concepts:**
```
Document â†’ Chunks â†’ Embeddings â†’ Vector Store
                                      â†“
Query â†’ Embedding â†’ Similarity Search â†’ Top-K Chunks
                                      â†“
                            Context + Query â†’ LLM â†’ Answer
```

---

### Sprint 4: Production RAG
**Skills:**
- LangChain framework
- Managed vector databases (Pinecone)
- RAG best practices
- Production deployment
- Monitoring & observability
- Cost optimization

**Deliverables:**
- LangChain-based RAG
- Pinecone integration
- Side-by-side comparison: Custom vs Framework
- Production-ready deployment
- Monitoring dashboard

**Architecture Comparison:**
```
Custom RAG (Sprint 3):
â”œâ”€â”€ Full control
â”œâ”€â”€ Lightweight
â”œâ”€â”€ Custom optimizations
â””â”€â”€ More code to maintain

LangChain RAG (Sprint 4):
â”œâ”€â”€ Quick to build
â”œâ”€â”€ Best practices built-in
â”œâ”€â”€ Rich ecosystem
â””â”€â”€ Less control over internals
```

---

## ğŸ“š Resources

### Sprint 1
- [Gemini API Docs](https://ai.google.dev/docs)
- [Gradio Documentation](https://gradio.app/docs)

### Sprint 2
- [OpenAI API Reference](https://platform.openai.com/docs)
- [Llama 3 Guide](https://llama.meta.com/)
- [Ollama Documentation](https://ollama.ai/)

### Sprint 3
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [Sentence Transformers](https://www.sbert.net/)
- [FAISS Documentation](https://faiss.ai/)

### Sprint 4
- [Pinecone Docs](https://docs.pinecone.io/)
- [LangChain Documentation](https://python.langchain.com/)
- [RAG Best Practices](https://www.pinecone.io/learn/retrieval-augmented-generation/)
